{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY2f9O3T_Ovk"
      },
      "source": [
        "# Neural Network Force-Free magnetic field extrapolation - NF2\n",
        "<img src=\"https://github.com/RobertJaro/NF2/blob/main/images/logo.jpg?raw=true\" width=\"150\" height=\"150\">\n",
        "\n",
        "This notebook uses NF2 to download and extrapolate vector magnetograms from SDO/HMI. Active regions and dates can be selected below.\n",
        "\n",
        "We use NF2 to extrapolate a time-series and to analyze the resulting magnetic energy build-up and release processes (e.g., flares).\n",
        "\n",
        "GitHub Page: https://github.com/RobertJaro/NF2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jJgVkX-MXsr"
      },
      "source": [
        "**Use**: A python notebook consists of code cells and embedded text descriptions. If you are using Google Colab all computations and installations are performed online, using free resources. You can execute the notebook cell-by-cell (hit `shift`+`return`), or run the full notebook by selecting `Runtime` --> `Run all` from the menu. Use the forms below to select the active region, date, and training parameters. For regular use you can keep the default training parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGdTQSN6GA6z"
      },
      "source": [
        "## Installation and Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deEBHLxM0Uqb"
      },
      "source": [
        "NF2 can be directly installed from the GitHub repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5_9wsH1cmsh"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/RobertJaro/NF2.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1fOxaJS5xH6"
      },
      "outputs": [],
      "source": [
        "# general imports\n",
        "import glob\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "from dateutil.parser import parse\n",
        "import shutil\n",
        "import gdown\n",
        "\n",
        "# download\n",
        "import drms\n",
        "from urllib import request\n",
        "\n",
        "# data processing\n",
        "import numpy as np\n",
        "from sunpy.map import Map\n",
        "from sunpy.net import Fido\n",
        "from sunpy.net import attrs as a\n",
        "\n",
        "# deep learning\n",
        "import torch\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, LambdaCallback\n",
        "import wandb\n",
        "\n",
        "# NF2\n",
        "from nf2.train.module import NF2Module, save\n",
        "from nf2.train.data_loader import SHARPDataModule, SHARPSeriesDataModule\n",
        "from nf2.data.download import download_HARP_series, find_HARP, download_euv\n",
        "from nf2.evaluation.unpack import load_cube\n",
        "from nf2.evaluation.metric import *\n",
        "from nf2.evaluation.energy import get_free_mag_energy\n",
        "from nf2.evaluation.series import evaluate_nf2_series\n",
        "from nf2.evaluation.flares import _calculate_free_energy, get_integrated_euv_map, load_B_map\n",
        "\n",
        "# visualization\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGrZwKgwGEro"
      },
      "source": [
        "## Data download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ8WH-7ABW8J"
      },
      "source": [
        "We start by downloading a series of SDO/HMI vector magnetograms. Use the forms below to set your email, and specify the active region that you are interested in (SHARP + date)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufn-xIQBCKS8"
      },
      "source": [
        "Downloading data requires an active registration at JSOC. http://jsoc.stanford.edu/ajax/register_email.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wJRSB1NV--Bb"
      },
      "outputs": [],
      "source": [
        "#@title Download Credentials\n",
        "jsoc_email = 'robert.jarolim@uni-graz.at' #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92DkBePsCiTd"
      },
      "outputs": [],
      "source": [
        "client = drms.Client(email=jsoc_email, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzBnLWbEB88F"
      },
      "source": [
        "If you are looking for a NOAA active region, you can use the function below to search for the corrsponding HARP number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zVLpXBf2oQN",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Start date of observation series\n",
        "year = 2017 #@param {type:\"integer\"}\n",
        "month = 9 #@param {type:\"integer\"}\n",
        "day = 6 #@param {type:\"integer\"}\n",
        "hour = 8 #@param {type:\"integer\"}\n",
        "minute = 36 #@param {type:\"number\"}\n",
        "\n",
        "date = datetime(year, month, day, hour, minute)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOb-ZnK40qt-",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Find SHARP number for given NOAA\n",
        "noaa_nums = [12673] #@param {type:\"\"}\n",
        "\n",
        "find_HARP(date, noaa_nums, client)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDUBoZ3-86en",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Active Region\n",
        "#@markdown (add the number from above here)\n",
        "sharp_nr = 7115 #@param {type:\"number\"}\n",
        "duration = '3h' # @param {type:\"string\"}\n",
        "\n",
        "date = datetime(year, month, day, hour, minute)\n",
        "\n",
        "download_dir = 'AR_7115' #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5FqGAP55UUO"
      },
      "source": [
        "Start download for time-series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1W22DbZHzYm4"
      },
      "outputs": [],
      "source": [
        "download_HARP_series(sharp_nr, date, duration, download_dir, client)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the first map in the series."
      ],
      "metadata": {
        "id": "fFQE-dKj5w6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Map(glob.glob(os.path.join(download_dir, '*Br.fits'))[0]).peek()"
      ],
      "metadata": {
        "id": "eV19mXCB5vd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlfpqlAyccTG"
      },
      "source": [
        "## Set parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovL6D7Az7_CO",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Paths\n",
        "base_path = None #@param {type:\"string\"}\n",
        "base_path = 'ar_%d_%s' % (sharp_nr, date.isoformat('T')) if base_path is None else base_path\n",
        "data_path = None #@param {type:\"string\"}\n",
        "data_path = download_dir if data_path is None else data_path\n",
        "\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "save_path = os.path.join(base_path, 'extrapolation_result.nf2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLeXpnuP6DHq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Data Parameters\n",
        "bin = 2 #@param {type:\"integer\"}\n",
        "spatial_norm = 160  #@param {type:\"integer\"}\n",
        "height = 160  #@param {type:\"integer\"}\n",
        "b_norm = 2500  #@param {type:\"number\"}\n",
        "d_slice =  None#@param {type:\"raw\"}\n",
        "potential_boundary = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "boundary = {'type': 'potential', 'strides': 4} if potential_boundary else {'type': 'open'}\n",
        "\n",
        "data_args = {\"data_path\": data_path,\n",
        "             \"height\":height,\n",
        "             \"spatial_norm\": spatial_norm,\n",
        "             \"b_norm\": b_norm,\n",
        "             \"work_directory\": base_path,\n",
        "             \"bin\": bin,\n",
        "             \"Mm_per_pixel\": 0.72,\n",
        "             \"slice\": d_slice,\n",
        "             \"boundar\": boundary\n",
        "             }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPAcHR4K6sU8",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Model Parameters\n",
        "#@markdown `dim = 64` &rarr; tiny\n",
        "\n",
        "#@markdown `dim = 256` &rarr; regular\n",
        "\n",
        "dim = 256 #@param {type:\"number\"}\n",
        "vector_potential = False #@param {type:\"boolean\"}\n",
        "\n",
        "model_args = {\"dim\": dim, \"use_vector_potential\": vector_potential}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KoeQGTp6t1B",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Training Parameters\n",
        "lambda_div = 0.1 #@param {type:\"number\"}\n",
        "lambda_ff = 0.1 #@param {type:\"number\"}\n",
        "\n",
        "iterations = 8e4 #@param {type:\"number\"}\n",
        "iterations = int(iterations)\n",
        "\n",
        "validation_interval = 1e4 #@param {type:\"number\"}\n",
        "validation_interval = int(validation_interval)\n",
        "\n",
        "\n",
        "batch_size = 1e4 #@param {type:\"number\"}\n",
        "batch_size = int(batch_size)\n",
        "\n",
        "data_args['iterations'] = iterations\n",
        "data_args['batch_size'] = batch_size\n",
        "training_args = {\"lambda_div\": lambda_div,\n",
        "              \"lambda_ff\": lambda_ff,}\n",
        "# combine args\n",
        "config = {'data': data_args, 'model': model_args, 'training': training_args}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KF8grbpIlnU"
      },
      "source": [
        "## Training - Extrapolation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the Weights and Biases (wandb) logger. The training results will be automatically uploaded during training and model checkpoints can be used to continue the model training."
      ],
      "metadata": {
        "id": "4BhHTCe7N3iM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQPv88a17_3Z"
      },
      "outputs": [],
      "source": [
        "wandb_logger = WandbLogger(project='nf2', name=str(sharp_nr), dir=base_path, log_model=\"all\")\n",
        "wandb_logger.experiment.config.update(config, allow_val_change=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Continue training from WandB\n",
        "#@markdown Enter your credentials if you want to continue an inturrpted run. This will restore the latest model and continue the training.\n",
        "wandb_id = \"\" #@param {type:\"string\"}\n",
        "wandb_entity = \"\" #@param {type:\"string\"}\n",
        "wandb_project = \"\" #@param {type:\"string\"}\n",
        "if wandb_id != \"\" and wandb_id is not None:\n",
        "    checkpoint_reference = f\"{wandb_entity}/{wandb_project}/model-{wandb_id}:latest\"\n",
        "    artifact = wandb_logger.use_artifact(checkpoint_reference, artifact_type=\"model\")\n",
        "    artifact.download(root=base_path)\n",
        "    shutil.move(os.path.join(base_path, 'model.ckpt'), os.path.join(base_path, 'last.ckpt'))\n",
        "    data_args['plot_overview'] = False  # skip overview plot for restored model"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Avh_MFrzdLVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXZj5mZY8Aqu"
      },
      "source": [
        "For logging we use WandB which allows us to monitor the traing process and saves our results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD8cJ9ZEC7E2"
      },
      "source": [
        "Before we start the extrapolation we need to process the downloaded data. The model requires the vector magnetogram and the corresponding error map. For this we use a data loader that automatically handles the processing of SHARPS according to the parameters set above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6Y-v3dA7GSc"
      },
      "outputs": [],
      "source": [
        "data_module = SHARPDataModule(**data_args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc7PUWtJV7qk"
      },
      "source": [
        "We initialize the NF2 model with the parameters from above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfEibAPOIoQS"
      },
      "outputs": [],
      "source": [
        "validation_settings = {'cube_shape': data_module.cube_dataset.coords_shape,\n",
        "                       'gauss_per_dB': b_norm,\n",
        "                       'Mm_per_ds': data_module.Mm_per_pixel * spatial_norm}\n",
        "\n",
        "nf2 = NF2Module(validation_settings, **model_args, **training_args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdkZvLIuWMqB"
      },
      "source": [
        "During training we log model states with callbacks that are used after every validation step. The models are then automatically synched to wandb. The extrapolation result (`.nf2` file) can be found in the file explorer on the left."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sP_20sNcV30S"
      },
      "outputs": [],
      "source": [
        "save_callback = LambdaCallback(\n",
        "    on_validation_end=lambda *args: save(save_path, nf2.model, data_module, config, nf2.height_mapping_model))\n",
        "checkpoint_callback = ModelCheckpoint(dirpath=base_path,\n",
        "                                      every_n_train_steps=validation_interval,\n",
        "                                      save_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwAd1rvJHsJJ"
      },
      "source": [
        "We initiliaze the traininer from pytorch lightning which handles the individual components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_yZENeDXh60"
      },
      "outputs": [],
      "source": [
        "n_gpus = torch.cuda.device_count()\n",
        "trainer = Trainer(max_epochs=1,\n",
        "                  logger=wandb_logger,\n",
        "                  devices=n_gpus if n_gpus >= 1 else None,\n",
        "                  accelerator='gpu' if n_gpus >= 1 else None,\n",
        "                  strategy='dp' if n_gpus > 1 else None,\n",
        "                  num_sanity_val_steps=0,\n",
        "                  val_check_interval=validation_interval,\n",
        "                  gradient_clip_val=0.1,\n",
        "                  callbacks=[checkpoint_callback, save_callback], )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCKi-HwKZY3h"
      },
      "source": [
        "Now we can start our model training. The training progress is automatically logged to wandb. Follow the link above to see the status and intermediate results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rs2CgBFmYY0e"
      },
      "outputs": [],
      "source": [
        "trainer.fit(nf2, data_module, ckpt_path='last')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As last step we save the trained model. If you continue an interrupted training run, excecude the code below to restore the nf2 file."
      ],
      "metadata": {
        "id": "8-BSQlguOjF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save(save_path, nf2.model, data_module, config, nf2.height_mapping_model)"
      ],
      "metadata": {
        "id": "ICNqfLUOOiXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT5wsu5xa5Nz"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-YDUsO5Vq-L"
      },
      "source": [
        "If you want to skip the training you can use the line below to download an example solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmjG-hDua2wc",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Download sample extrapolation result\n",
        "download = False #@param {type:\"boolean\"}\n",
        "tiny = False #@param {type:\"boolean\"}\n",
        "if download:\n",
        "  if tiny:\n",
        "    gdown.download('https://drive.google.com/uc?id=1BwvEtsw10pE18RDfSPnCKy3476FqV47_', save_path)\n",
        "  else:\n",
        "    gdown.download('https://drive.google.com/uc?id=1m57uDWSOiTd0cYUpZGr7nQ5HO00iTePl', save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZklkaZOjHJUg"
      },
      "source": [
        "It is important that the resutls are checked after the extrapolation is finished. The NF2 package provides metrics that can be used to estimate the quality. Both the divergence and the angle between the currents and magnetic field should be small. (ideally mean divergence `<0.1` and sigma `<10` degree; the exact values depend on the selected active region and lambda weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EEaBAvoIwHT"
      },
      "source": [
        "From the save file we can load the full simulation volume."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzP-QmwWHiHC"
      },
      "outputs": [],
      "source": [
        "b = load_cube(save_path, progress=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3I5u8oSSbKA"
      },
      "source": [
        "The loaded mesh can be used to compute the divergence and the sigma angle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pnj8vZ1YSarz"
      },
      "outputs": [],
      "source": [
        "n_div = (np.abs(divergence(b)) / vector_norm(b)).mean()\n",
        "theta = weighted_theta(b)\n",
        "\n",
        "print('DIVERGENCE [1/pix]: %.04f; THETA [deg] %.04f' % (n_div, theta))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtBgyVytQW7Q"
      },
      "source": [
        "We can also compute maps of integrated current density."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZYuXgvPQcqX"
      },
      "outputs": [],
      "source": [
        "j = curl(b)\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(121)\n",
        "plt.imshow(b[:, :, 0, 2].T, vmin=-2500, vmax=2500, cmap='gray')\n",
        "plt.title('$B_z$')\n",
        "plt.axis('off')\n",
        "plt.subplot(122)\n",
        "plt.imshow(vector_norm(j).sum(2).T, origin='lower', cmap='inferno')\n",
        "plt.title('Current Density')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCSKCiYQSEDP"
      },
      "source": [
        "By computing the potential field we can estimate the free magnetic energy, and visualize the result as integrated map. Here, we only consider the first 64 grid cells in height for faster computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvxjBEGSSXXR"
      },
      "outputs": [],
      "source": [
        "free_me = get_free_mag_energy(b[:, :, :64])\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.imshow(free_me.sum(2).transpose(), origin='lower')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyC2vVbza7fN"
      },
      "source": [
        "## Export"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Ic38DF-DTFlW"
      },
      "source": [
        "VTK files can be used to visualize the extrapolation results (e.g., Paraview). We use `tvtk` for converting the files.\n",
        "The NF2 results require little storage (about 2 MB). It is faster to download the NF2 file and convert it on your local environment using the CPU resources.\n",
        "\n",
        "The code below can be used to convert files in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnN9andvcdF8"
      },
      "outputs": [],
      "source": [
        "!pip install vtk==9.0.1\n",
        "!pip install mayavi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2F0OBfVZbEMr"
      },
      "outputs": [],
      "source": [
        "from nf2.evaluation.unpack import load_cube\n",
        "from nf2.evaluation.vtk import save_vtk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aphkhjLva6NK"
      },
      "outputs": [],
      "source": [
        "model_path = base_path + '/extrapolation_result.nf2'\n",
        "vtk_path = base_path + '/extrapolation_result.vtk'\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "b = load_cube(model_path, device, progress=True)\n",
        "save_vtk(b, vtk_path, 'B')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjS3CgWqVL-d"
      },
      "source": [
        "## Training - Series Extrapolation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0FOZxs9YuEY"
      },
      "source": [
        "Starting from our previous extrapolation, we can significantly speed-up the extrapolation of the temporal evolution. For this we adapt the model sequentially by changing the boundary condition and re-training the model. This allows us to converge within few iterations per time step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWmovrrQZOsn"
      },
      "source": [
        "We start by downloading the data. Fill the form below to select your time range. Note that we use the same start point and sharp as in the previous extrapolation (i.e., we require an initial extrapolation)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq-PHrsSD_2i"
      },
      "source": [
        "To skip the initial training you can download the pre-trained state by running the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFsq_XVqpO4x",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Series parameters\n",
        "step_iterations = 2e3 #@param {type:\"number\"}\n",
        "check_val_every_n_epoch =  100 #@param {type:\"integer\"}\n",
        "\n",
        "series_data_args = {**data_args}\n",
        "series_data_args['iterations'] = int(step_iterations)\n",
        "del series_data_args['data_path']\n",
        "\n",
        "series_training_args = {**training_args}\n",
        "series_training_args['lambda_b'] = 1\n",
        "series_training_args['lr_params'] = 5e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the logging to wandb."
      ],
      "metadata": {
        "id": "OZdcZMV27Xkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()\n",
        "wandb_logger = WandbLogger(project='nf2', name=str(sharp_nr) + '_series', dir=base_path, log_model=\"all\")\n",
        "wandb_logger.experiment.config.update(config, allow_val_change=True)"
      ],
      "metadata": {
        "id": "qmlDZjwH7W31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We prepare the data loader which will sequentially update the boundary condtion of the magnetic field extrapolation."
      ],
      "metadata": {
        "id": "AitTLhPx5vwl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmEdIi04hzFF"
      },
      "outputs": [],
      "source": [
        "hmi_p_files = sorted(glob.glob(os.path.join(data_path, '*Bp.fits')))  # x\n",
        "hmi_t_files = sorted(glob.glob(os.path.join(data_path, '*Bt.fits')))  # y\n",
        "hmi_r_files = sorted(glob.glob(os.path.join(data_path, '*Br.fits')))  # z\n",
        "err_p_files = sorted(glob.glob(os.path.join(data_path, '*Bp_err.fits')))  # x\n",
        "err_t_files = sorted(glob.glob(os.path.join(data_path, '*Bt_err.fits')))  # y\n",
        "err_r_files = sorted(glob.glob(os.path.join(data_path, '*Br_err.fits')))  # z\n",
        "\n",
        "data_paths = list(zip(hmi_p_files, err_p_files, hmi_t_files, err_t_files, hmi_r_files, err_r_files))\n",
        "data_module = SHARPSeriesDataModule(data_paths, **series_data_args)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We re-initialize the model and use the previous model as initial starting point (`meta_path`)"
      ],
      "metadata": {
        "id": "VEKTlnu553iE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhpsXddAh9XV"
      },
      "outputs": [],
      "source": [
        "nf2 = NF2Module(validation_settings, meta_path=save_path, **model_args, **series_training_args)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model checkpoints are saved every epoch before we update the boundary condition. The resulting nf2 files correspond then to the frames of the series."
      ],
      "metadata": {
        "id": "Zoa9McGG6GtL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soDvM3rNnyqF"
      },
      "outputs": [],
      "source": [
        "save_callback = LambdaCallback(on_train_epoch_end=lambda *args: save(\n",
        "    os.path.join(base_path, os.path.basename(data_paths[nf2.current_epoch][0]).split('.')[-3] + '.nf2'),\n",
        "    nf2.model, data_module, config, nf2.height_mapping_model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdi3DjPfhnbm"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(max_epochs=len(data_paths),\n",
        "                  logger=wandb_logger,\n",
        "                  devices=n_gpus if n_gpus >= 1 else None,\n",
        "                  accelerator='gpu' if n_gpus >= 1 else None,\n",
        "                  strategy='dp' if n_gpus > 1 else None,\n",
        "                  num_sanity_val_steps=0, callbacks=[save_callback],\n",
        "                  gradient_clip_val=0.1, reload_dataloaders_every_n_epochs=1,\n",
        "                  check_val_every_n_epoch=check_val_every_n_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5qHAfiOp0F3"
      },
      "outputs": [],
      "source": [
        "trainer.fit(nf2, data_module)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation  - Series"
      ],
      "metadata": {
        "id": "zkV9nsGF6pO_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ncM70ydD9m0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Download sample extrapolation result\n",
        "download = False #@param {type:\"boolean\"}\n",
        "if download:\n",
        "  zip_path = os.path.join(base_path, 'nf2_series.zip')\n",
        "  gdown.download('https://drive.google.com/uc?id=1lkbPC7r8EiIrNp_h14Dj_DUKzwpkR60x', zip_path)\n",
        "  shutil.unpack_archive(zip_path, base_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nf2_files = sorted(glob.glob(os.path.join(base_path, '*.nf2')))\n",
        "nf2_files = [f for f in nf2_files if 'extrapolation_result.nf2' not in f] # filter the initial state\n",
        "\n",
        "state = torch.load(nf2_files[0], map_location='cpu')\n",
        "Mm_per_pix = state['Mm_per_pixel']\n",
        "cm_per_pix = (Mm_per_pix * 1e8)\n",
        "z_pixels = int(np.ceil(20 / (Mm_per_pix)))\n",
        "\n",
        "series_results = evaluate_nf2_series(nf2_files, z_pixels, cm_per_pix, 2, batch_size)"
      ],
      "metadata": {
        "id": "OA-NJpAUK4Wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lby5AjxY_NO0"
      },
      "source": [
        "Registered flares in this sequence: X2.2 - 08:57; C5.4 - 10:13; X9.3 - 11:53"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOpBr-s1_Y93"
      },
      "outputs": [],
      "source": [
        "# plot the integrated free magnetic energy\n",
        "plt.figure(figsize=(9, 3))\n",
        "plt.plot(series_results['date'], np.array(series_results['total_free_energy']) * 1e-32)\n",
        "plt.ylabel('Free Energy\\n[$10^{32}$ erg]')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Flare Event"
      ],
      "metadata": {
        "id": "NBW3W6zcFRuL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The magnetic field extrapolations can be used to compare the energy change to flare events and locate regions of strong energy release.\n",
        "\n",
        "We use `Fido` to find registered flares in our series."
      ],
      "metadata": {
        "id": "nEMcfv6pFYoP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEMIl6UW4Ipb"
      },
      "outputs": [],
      "source": [
        "dates = [parse(os.path.basename(nf2_file).split('.')[0][:-4].replace('_', 'T')) for nf2_file in nf2_files]\n",
        "flares = Fido.search(a.Time(min(dates), max(dates)),\n",
        "                     a.hek.EventType(\"FL\"),\n",
        "                     a.hek.OBS.Observatory == \"GOES\")[\"hek\"]\n",
        "#flares = [f for f in flares if f[\"fl_goescls\"][0] in ['M', 'X']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flares[['event_starttime', 'fl_goescls']]"
      ],
      "metadata": {
        "id": "E88ha_WyYH0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the list above to select the flare event you are interested in."
      ],
      "metadata": {
        "id": "i8IQvuABajPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flare = list(flares)[3] # select flare"
      ],
      "metadata": {
        "id": "AkW32-lpGW5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We download EUV observations as reference for comparison."
      ],
      "metadata": {
        "id": "OjyxiwLHarNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = flare[\"event_starttime\"].datetime\n",
        "end_time = flare[\"event_endtime\"].datetime\n",
        "euv_files = download_euv(start_time, end_time, download_dir, client=client)"
      ],
      "metadata": {
        "id": "1yJ-64lsaL0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filter_dates = (np.array(dates) > (start_time - timedelta(minutes=12))) & \\\n",
        "                (np.array(dates) < (end_time + timedelta(minutes=12)))\n",
        "flare_nf2_files = np.array(nf2_files)[filter_dates]\n",
        "\n",
        "free_energy_0 = _calculate_free_energy(flare_nf2_files[0], z_pixels, batch_size)\n",
        "free_energy_1 = _calculate_free_energy(flare_nf2_files[-1], z_pixels, batch_size)\n",
        "released_energy = -np.clip(free_energy_0 - free_energy_1, a_min=None, a_max=0)\n",
        "released_energy_map = released_energy.sum(2) * cm_per_pix\n",
        "\n",
        "mag_map = load_B_map(flare_nf2_files[0])\n",
        "euv_map = get_integrated_euv_map(euv_files, mag_map.wcs)\n",
        "\n",
        "plt.figure(figsize=(15, 3))\n",
        "\n",
        "plt.subplot(131, projection=mag_map)\n",
        "mag_map.plot()\n",
        "plt.title('$B_z$')\n",
        "\n",
        "plt.subplot(132, projection=euv_map)\n",
        "plt.imshow(euv_map.data, origin='lower', cmap='sdoaia94', norm=ImageNormalize(stretch=AsinhStretch(0.005)))\n",
        "plt.title('Integrated EUV SDO/AIA 94 $\\AA$')\n",
        "plt.xlabel('Carrington Longitude')\n",
        "plt.ylabel(' ')\n",
        "\n",
        "plt.subplot(133, projection=mag_map)\n",
        "im = plt.imshow(released_energy_map.T, origin='lower', cmap='jet')\n",
        "plt.title(f'Released energy [{released_energy.sum() * cm_per_pix ** 3:.2e} erg]')\n",
        "plt.xlabel('Carrington Longitude')\n",
        "plt.ylabel(' ')\n",
        "plt.colorbar(mappable=im, label='erg/cm$^2$')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "sdbWfm3vF58U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hBjzDuBCZSmu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}